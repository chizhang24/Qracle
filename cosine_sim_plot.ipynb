{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"pgf.texsystem\": \"pdflatex\",\n",
    "    \"text.usetex\": False,  # Turn this OFF to prevent LaTeX errors\n",
    "    \"font.family\": \"serif\",\n",
    "    \"pgf.rcfonts\": False,\n",
    "\n",
    "    \"axes.labelsize\": 14,  # Increase label font size\n",
    "    \"axes.titlesize\": 16,  # Increase title font size\n",
    "    \"legend.fontsize\": 12,  # Increase legend font size\n",
    "    \"xtick.labelsize\": 15,  # Increase x-axis tick size\n",
    "    \"ytick.labelsize\": 15,  # Increase y-axis tick size\n",
    "    \"lines.linewidth\": 2.5,  # Make lines thicker\n",
    "    \"lines.markersize\": 8,  # Increase marker size\n",
    "    \"grid.alpha\": 0.3,  # Make grid less prominent\n",
    "    \"figure.figsize\": (4, 3),  # Set consistent figure size\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heisenberg_valid_file = 'data/heisenberg_xyz_valid.h5'\n",
    "ti_valid_file = 'data/ti_valid.h5'\n",
    "fh_valid_file = 'data/fh_valid.h5'\n",
    "\n",
    "molecule_valid_file = 'data/h2_valid.h5'\n",
    "\n",
    "vqe_valid_file = 'data/random_vqe_valid.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cosine_sim(valid_file, model_name='Heisenberg XYZ'):\n",
    "    opt_vec = []\n",
    "    diff_vec = []\n",
    "    q_vec = []\n",
    "    with h5py.File(valid_file,'r') as f:\n",
    "\n",
    "        opt_param_group = f['model_param']\n",
    "        diff_param_group = f['diff_model_param']\n",
    "        q_param_group = f['dgnn_model_param']\n",
    "        keys = list(opt_param_group.keys())\n",
    "        \n",
    "        for key in keys:\n",
    "            opt_param = opt_param_group[key][...]\n",
    "            opt_param = opt_param.flatten()\n",
    "            diff_param = diff_param_group[key][...]\n",
    "            diff_param = diff_param.flatten()\n",
    "            q_param = q_param_group[key][...]\n",
    "            q_param = q_param.flatten()\n",
    "            opt_vec.append(opt_param)\n",
    "            diff_vec.append(diff_param)\n",
    "            q_vec.append(q_param)\n",
    "        \n",
    "    n_samples = len(opt_vec)\n",
    "\n",
    "    sim_opt_diff = [cosine_similarity(opt_vec[i].reshape(1, -1), diff_vec[i].reshape(1, -1))[0,0] for i in range(n_samples)]\n",
    "    sim_opt_q = [cosine_similarity(opt_vec[i].reshape(1, -1), q_vec[i].reshape(1, -1))[0,0] for i in range(n_samples)]\n",
    "\n",
    "\n",
    "    sim_opt_diff = np.array(sim_opt_diff)\n",
    "    sim_opt_q = np.array(sim_opt_q)\n",
    "\n",
    "    sim_o_d_w = np.ones_like(sim_opt_diff) / (len(sim_opt_diff))\n",
    "\n",
    "    sim_o_q_w = np.ones_like(sim_opt_q) / (len(sim_opt_q))\n",
    "\n",
    "\n",
    "    bins = 80 \n",
    "\n",
    "    hist_1, _ = np.histogram(sim_opt_diff, bins=bins, weights=sim_o_d_w)\n",
    "    hist_2, _ = np.histogram(sim_opt_q, bins=bins, weights=sim_o_q_w)\n",
    "\n",
    "    max_val = max(np.max(hist_1), np.max(hist_2))\n",
    "    plt.figure()\n",
    "\n",
    "    colors = ['limegreen', 'lightcoral']\n",
    "\n",
    "    names = ['Diffusion', 'GNN']\n",
    "\n",
    "    plt.hist([sim_opt_diff, sim_opt_q], bins=80, weights=[sim_o_d_w, sim_o_q_w], alpha=0.9, color=colors, label=names)\n",
    "    \n",
    "    y_top = max_val * 1.1\n",
    "\n",
    "    yticks = np.linspace(0, y_top, 6)  # Define Y-ticks explicitly\n",
    "\n",
    "    plt.yticks(yticks,labels=[f\"{y:.2f}\" for y in yticks] )\n",
    "    plt.legend()\n",
    "    # plt.title(f'Cosine Similarity Distribution for {model_name}')\n",
    "    plt.xlabel('Cosine Similarity')\n",
    "    plt.ylabel('Probability Density')\n",
    "\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(f\"{model_name.replace(' ', '_')}_Cosine_Similarity.pdf\", dpi=300, bbox_inches='tight', format=\"pdf\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_qasm_vqe_final_loss(vqe_valid_file, n_steps):\n",
    "\n",
    "    with h5py.File(vqe_valid_file, 'r') as f:\n",
    "        random_loss_hist_group = f['loss_history']\n",
    "        diff_loss_hist_group = f['diff_loss_history']\n",
    "        q_loss_hist_group = f['dgnn_loss_history']\n",
    "        ground_final_loss = []\n",
    "        diff_final_loss = []\n",
    "        q_final_loss = []\n",
    "        rand_final_loss = []\n",
    "        keys = list(random_loss_hist_group.keys())\n",
    "        for key in keys: \n",
    "            random_loss_hist = random_loss_hist_group[key][...]\n",
    "            diff_loss_hist = diff_loss_hist_group[key][...]\n",
    "            q_loss_hist = q_loss_hist_group[key][...]\n",
    "            ground_final_loss.append(random_loss_hist[-1][1])\n",
    "            diff_final_loss.append(diff_loss_hist[n_steps][1])\n",
    "            q_final_loss.append(q_loss_hist[n_steps][1])\n",
    "            rand_final_loss.append(random_loss_hist[n_steps][1])\n",
    "\n",
    "    return ground_final_loss, diff_final_loss, q_final_loss, rand_final_loss\n",
    "\n",
    "\n",
    "def get_final_loss(valid_file, n_steps):\n",
    "\n",
    "    with h5py.File(valid_file, 'r') as f:\n",
    "        random_loss_hist_group = f['loss_history']\n",
    "        diff_loss_hist_group = f['diff_loss_history']\n",
    "        q_loss_hist_group = f['dgnn_loss_history']\n",
    "        ground_final_loss = []\n",
    "        diff_final_loss = []\n",
    "        q_final_loss = []\n",
    "        rand_final_loss = []\n",
    "        keys = list(random_loss_hist_group.keys())\n",
    "        for key in keys: \n",
    "            random_loss_hist = random_loss_hist_group[key][...]\n",
    "            diff_loss_hist = diff_loss_hist_group[key][...]\n",
    "            q_loss_hist = q_loss_hist_group[key][...]\n",
    "            ground_final_loss.append(random_loss_hist[-1])\n",
    "            diff_final_loss.append(diff_loss_hist[n_steps])\n",
    "            q_final_loss.append(q_loss_hist[n_steps])\n",
    "            rand_final_loss.append(random_loss_hist[n_steps])\n",
    "\n",
    "    return ground_final_loss, diff_final_loss, q_final_loss, rand_final_loss\n",
    "\n",
    "\n",
    "def compute_mre(y_label, y_pred):\n",
    "    mask = y_label != 0\n",
    "    return np.mean(np.abs((y_label[mask] - y_pred[mask]) / y_label[mask])) * 100  # MRE in percentage\n",
    "\n",
    "\n",
    "def compute_smape(y_label, y_pred):\n",
    "    mask = (y_label + y_pred) != 0\n",
    "    return np.mean(np.abs(y_label[mask] - y_pred[mask]) / ((np.abs(y_label[mask]) + np.abs(y_pred[mask])) / 2)) * 100  # sMAPE in percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_confusion_matrix(ground_energy, q_energy, model_name='QASMBench VQE', color = 'lightcoral', if_diffusion = False):\n",
    "    mre = compute_mre(np.array(ground_energy), np.array(q_energy))\n",
    "\n",
    "\n",
    "    min_val = min(np.min(ground_energy), np.min(q_energy))\n",
    "    max_val = max(np.max(ground_energy), np.max(q_energy))\n",
    "\n",
    "    x_line = np.linspace(min_val, max_val, 100)\n",
    "\n",
    "    xtick = np.linspace(min_val, max_val, 5)\n",
    "    ytick = np.linspace(min_val, max_val, 5)\n",
    "    plt.figure()\n",
    "\n",
    "\n",
    "\n",
    "    plt.scatter(ground_energy,q_energy, color=color, label = f'MRE = {mre: .2f}%')\n",
    "\n",
    "    plt.plot(x_line, x_line, color='gray', linestyle='--')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.xlabel(r'$E_{label}$')\n",
    "    if if_diffusion:\n",
    "        plt.ylabel(r'$E_{Diffusion}$')\n",
    "    else:\n",
    "        plt.ylabel(r'$E_{GNN}$')\n",
    "    # plt.ylabel(r'$E_{Qracle}$')\n",
    "    plt.xticks(xtick, labels=[f\"{x:.2f}\" for x in xtick])\n",
    "    plt.yticks(ytick, labels=[f\"{y:.2f}\" for y in ytick])\n",
    "\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    # plt.title(f'Confusion Matrix for {model_name}')\n",
    "\n",
    "    plt.savefig(f\"{model_name.replace(' ', '_')}_Confusion_Matrix.pdf\", dpi=300, bbox_inches='tight', format=\"pdf\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def get_init_losses(valid_file):\n",
    "    \"\"\"Reads the initial losses from the validation file.\"\"\"\n",
    "    random_init, diff_init, dgnn_init, gin_init = [], [], [], []\n",
    "\n",
    "    # Read Data\n",
    "    with h5py.File(valid_file, 'r') as f:\n",
    "        for key in f['loss_history'].keys():\n",
    "            random_init.append(f['loss_history'][key][0])\n",
    "            diff_init.append(f['diff_loss_history'][key][0])\n",
    "            dgnn_init.append(f['dgnn_loss_history'][key][0])\n",
    "            gin_init.append(f['gin_loss_history'][key][0])\n",
    "\n",
    "    return random_init, diff_init, dgnn_init, gin_init\n",
    "\n",
    "\n",
    "\n",
    "def get_qasm_vqe_init_losses(valid_file):\n",
    "\n",
    "    \"\"\"Reads the initial losses from the QASM VQE validation file.\"\"\"\n",
    "    random_init, diff_init, dgnn_init, gin_init = [], [], [], []\n",
    "\n",
    "    # Read Data\n",
    "    with h5py.File(valid_file, 'r') as f:\n",
    "        for key in f['loss_history'].keys():\n",
    "            random_init.append(f['loss_history'][key][0, 1])\n",
    "            diff_init.append(f['diff_loss_history'][key][0, 1])\n",
    "            dgnn_init.append(f['dgnn_loss_history'][key][0, 1])\n",
    "            gin_init.append(f['gin_loss_history'][key][0, 1])\n",
    "\n",
    "    return random_init, diff_init, dgnn_init, gin_init\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_qasm_conv_steps(valid_file, percentage_threshold=0.0001, plateau_steps=10):\n",
    "    def get_steps_to_convergence(loss_history, percentage_threshold, plateau_steps):\n",
    "        loss_values = loss_history[:, 1]\n",
    "        total_height = max(loss_values) - min(loss_values)\n",
    "        steps_to_convergence = len(loss_values)\n",
    "\n",
    "        for i in range(len(loss_values)-plateau_steps):\n",
    "            percentage_changes = [abs(loss_values[i+j+1] - loss_values[i+j])/total_height for j in range(plateau_steps)]\n",
    "            if all (change < percentage_threshold for change in percentage_changes):\n",
    "                steps_to_convergence = loss_history[i, 0]\n",
    "                break\n",
    "\n",
    "        return steps_to_convergence\n",
    "    \n",
    "    rand_conv_steps, diff_conv_steps, q_conv_steps = [], [], []\n",
    "\n",
    "    with h5py.File(valid_file, 'r') as f:\n",
    "        rand_loss_history_group = f['loss_history']\n",
    "        diff_loss_history_group = f['diff_loss_history']\n",
    "        q_loss_history_group = f['dgnn_loss_history']\n",
    " \n",
    "        for key in rand_loss_history_group.keys():\n",
    "            rand_loss_history = rand_loss_history_group[key][...]\n",
    "            diff_loss_history = diff_loss_history_group[key][...]\n",
    "            q_loss_history = q_loss_history_group[key][...]\n",
    "\n",
    "            rand_steps_to_convergence = get_steps_to_convergence(rand_loss_history, percentage_threshold, plateau_steps)\n",
    "            diff_steps_to_convergence = get_steps_to_convergence(diff_loss_history, percentage_threshold, plateau_steps)\n",
    "            q_steps_to_convergence = get_steps_to_convergence(q_loss_history, percentage_threshold, plateau_steps)\n",
    "\n",
    "            rand_conv_steps.append(rand_steps_to_convergence)\n",
    "            diff_conv_steps.append(diff_steps_to_convergence)\n",
    "            q_conv_steps.append(q_steps_to_convergence)\n",
    "    return rand_conv_steps, diff_conv_steps, q_conv_steps\n",
    "    \n",
    "\n",
    "def get_conv_steps(valid_file, percentage_threshold=0.0001, plateau_steps=10):\n",
    "    def get_steps_to_convergence(loss_history, percentage_threshold, plateau_steps):\n",
    "        loss_values = loss_history\n",
    "        total_height = max(loss_values) - min(loss_values)\n",
    "        steps_to_convergence = len(loss_values)\n",
    "\n",
    "        for i in range(len(loss_values)-plateau_steps):\n",
    "            percentage_changes = [abs(loss_values[i+j+1] - loss_values[i+j])/total_height for j in range(plateau_steps)]\n",
    "            if all (change < percentage_threshold for change in percentage_changes):\n",
    "                steps_to_convergence = i + plateau_steps\n",
    "                break\n",
    "\n",
    "        return steps_to_convergence\n",
    "    \n",
    "    rand_conv_steps, diff_conv_steps, q_conv_steps = [], [], []\n",
    "\n",
    "    with h5py.File(valid_file, 'r') as f:\n",
    "        rand_loss_history_group = f['loss_history']\n",
    "        diff_loss_history_group = f['diff_loss_history']\n",
    "        q_loss_history_group = f['dgnn_loss_history']\n",
    " \n",
    "        for key in rand_loss_history_group.keys():\n",
    "            rand_loss_history = rand_loss_history_group[key][...]\n",
    "            diff_loss_history = diff_loss_history_group[key][...]\n",
    "            q_loss_history = q_loss_history_group[key][...]\n",
    "\n",
    "            rand_steps_to_convergence = get_steps_to_convergence(rand_loss_history, percentage_threshold, plateau_steps)\n",
    "            diff_steps_to_convergence = get_steps_to_convergence(diff_loss_history, percentage_threshold, plateau_steps)\n",
    "            q_steps_to_convergence = get_steps_to_convergence(q_loss_history, percentage_threshold, plateau_steps)\n",
    "\n",
    "            rand_conv_steps.append(rand_steps_to_convergence)\n",
    "            diff_conv_steps.append(diff_steps_to_convergence)\n",
    "            q_conv_steps.append(q_steps_to_convergence)\n",
    "    return rand_conv_steps, diff_conv_steps, q_conv_steps\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heisenberg Random sMAPE: 8.96%, after 200 steps\n",
      "Heisenberg Diffusion sMAPE: 9.77%, after 200 steps\n",
      "Heisenberg Qracle sMAPE: 4.09%, after 200 steps\n",
      "Heisenberg Random MRE: 7.48%, after 200 steps\n",
      "Heisenberg Diffusion MRE: 8.14%, after 200 steps\n",
      "Heisenberg Qracle MRE: 3.52%, after 200 steps\n",
      "Transverse Ising Random sMAPE: 2.84%, after 200 steps\n",
      "Transverse Ising Diffusion sMAPE: 2.27%, after 200 steps\n",
      "Transverse Ising Qracle sMAPE: 0.39%, after 200 steps\n",
      "Transverse Ising Random MRE: 2.67%, after 200 steps\n",
      "Transverse Ising Diffusion MRE: 1.96%, after 200 steps\n",
      "Transverse Ising Qracle MRE: 0.37%, after 200 steps\n",
      "Fermi-Hubbard Random sMAPE: 13.54%, after 200 steps\n",
      "Fermi-Hubbard Diffusion sMAPE: 21.50%, after 200 steps\n",
      "Fermi-Hubbard Qracle sMAPE: 15.07%, after 200 steps\n",
      "Fermi-Hubbard Random MRE: 2133588677850728.50%, after 200 steps\n",
      "Fermi-Hubbard Diffusion MRE: 1185068051145976.00%, after 200 steps\n",
      "Fermi-Hubbard Qracle MRE: 1337957154529.60%, after 200 steps\n",
      "H2 Random sMAPE: 2.01%, after 200 steps\n",
      "H2 Diffusion sMAPE: 58.17%, after 200 steps\n",
      "H2 Qracle sMAPE: 31.83%, after 200 steps\n",
      "H2 Random MRE: 1.93%, after 200 steps\n",
      "H2 Diffusion MRE: 46.67%, after 200 steps\n",
      "H2 Qracle MRE: 26.74%, after 200 steps\n"
     ]
    }
   ],
   "source": [
    "valid_files = [heisenberg_valid_file, ti_valid_file, fh_valid_file, molecule_valid_file]\n",
    "\n",
    "model_names = ['Heisenberg', 'Transverse Ising', 'Fermi-Hubbard', 'H2']\n",
    "\n",
    "n_steps = 200\n",
    "\n",
    "for valid_file, model_name in zip(valid_files, model_names):\n",
    "    ground_energy, diff_energy, q_energy, rand_energy = get_final_loss(valid_file, n_steps=n_steps)\n",
    "    # plot_confusion_matrix(ground_energy, q_energy, model_name=model_name + 'GNN', color='lightcoral', if_diffusion=False)\n",
    "    # plot_confusion_matrix(ground_energy, diff_energy, model_name=model_name + 'Diffusion', color='limegreen', if_diffusion=True)\n",
    "\n",
    "    # plot_cosine_sim(valid_file, model_name=model_name)\n",
    "    rand_mre = compute_mre(np.array(ground_energy), np.array(rand_energy))\n",
    "    q_mre = compute_mre(np.array(ground_energy), np.array(q_energy))\n",
    "\n",
    "    diff_mre = compute_mre(np.array(ground_energy), np.array(diff_energy))\n",
    "    \n",
    "    rand_smape = compute_smape(np.array(ground_energy), np.array(rand_energy))\n",
    "    q_smape = compute_smape(np.array(ground_energy), np.array(q_energy))\n",
    "    diff_smape = compute_smape(np.array(ground_energy), np.array(diff_energy))\n",
    "\n",
    "\n",
    "    print(f\"{model_name} Random sMAPE: {rand_smape:.2f}%, after {n_steps} steps\")\n",
    "    print(f\"{model_name} Diffusion sMAPE: {diff_smape:.2f}%, after {n_steps} steps\")\n",
    "    print(f\"{model_name} Qracle sMAPE: {q_smape:.2f}%, after {n_steps} steps\")\n",
    "\n",
    "\n",
    "    print(f\"{model_name} Random MRE: {rand_mre:.2f}%, after {n_steps} steps\")\n",
    "    print(f\"{model_name} Diffusion MRE: {diff_mre:.2f}%, after {n_steps} steps\")\n",
    "    print(f\"{model_name} Qracle MRE: {q_mre:.2f}%, after {n_steps} steps\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QASM VQE Random sMAPE: 0.40%, after 200 steps\n",
      "QASM VQE Diffusion sMAPE: 0.80%, after 200 steps\n",
      "QASM VQE Qracle sMAPE: 0.40%, after 200 steps\n",
      "QASM VQE Random MRE: 0.40%, after 200 steps\n",
      "QASM VQE Diffusion MRE: 0.78%, after 200 steps\n",
      "QASM VQE Qracle MRE: 0.40%, after 200 steps\n"
     ]
    }
   ],
   "source": [
    "ground_energy, diff_energy, q_energy, rand_energy= get_qasm_vqe_final_loss(vqe_valid_file, n_steps=n_steps)\n",
    "\n",
    "qasm_q_mre = compute_mre(np.array(ground_energy), np.array(q_energy))\n",
    "qasm_diff_mre = compute_mre(np.array(ground_energy), np.array(diff_energy))\n",
    "qasm_rand_mre = compute_mre(np.array(ground_energy), np.array(rand_energy))\n",
    "qasm_q_smape = compute_smape(np.array(ground_energy), np.array(q_energy))\n",
    "qasm_diff_smape = compute_smape(np.array(ground_energy), np.array(diff_energy))\n",
    "qasm_rand_smape = compute_smape(np.array(ground_energy), np.array(rand_energy))\n",
    "print(f\"QASM VQE Random sMAPE: {qasm_rand_smape:.2f}%, after {n_steps} steps\")\n",
    "print(f\"QASM VQE Diffusion sMAPE: {qasm_diff_smape:.2f}%, after {n_steps} steps\")\n",
    "print(f\"QASM VQE Qracle sMAPE: {qasm_q_smape:.2f}%, after {n_steps} steps\")\n",
    "\n",
    "print(f\"QASM VQE Random MRE: {qasm_rand_mre:.2f}%, after {n_steps} steps\")\n",
    "print(f\"QASM VQE Diffusion MRE: {qasm_diff_mre:.2f}%, after {n_steps} steps\")\n",
    "print(f\"QASM VQE Qracle MRE: {qasm_q_mre:.2f}%, after {n_steps} steps\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heisenberg Random Init Loss: 0.06\n",
      "Heisenberg Diff Init Loss: -0.16\n",
      "Heisenberg Qracle Init Loss: -3.11\n",
      "Transverse Ising Random Init Loss: -3.23\n",
      "Transverse Ising Diff Init Loss: -12.18\n",
      "Transverse Ising Qracle Init Loss: -23.04\n",
      "Fermi-Hubbard Random Init Loss: 1.01\n",
      "Fermi-Hubbard Diff Init Loss: 0.47\n",
      "Fermi-Hubbard Qracle Init Loss: -0.80\n",
      "H2 Random Init Loss: -0.22\n",
      "H2 Diff Init Loss: -0.36\n",
      "H2 Qracle Init Loss: -0.58\n"
     ]
    }
   ],
   "source": [
    "for valid_file, model_name in zip(valid_files, model_names):\n",
    "    random_init, diff_init, dgnn_init, _ = get_init_losses(valid_file)\n",
    "    random_mean_init = np.mean(random_init)\n",
    "    diff_mean_init = np.mean(diff_init)\n",
    "    dgnn_mean_init = np.mean(dgnn_init)\n",
    "    print(f\"{model_name} Random Init Loss: {random_mean_init:.2f}\")\n",
    "    print(f\"{model_name} Diff Init Loss: {diff_mean_init:.2f}\")\n",
    "    print(f\"{model_name} Qracle Init Loss: {dgnn_mean_init:.2f}\")\n",
    "\n",
    "    # plot_confusion_matrix(random_init, diff_init, model_name=model_name + 'Diffusion', color='limegreen', if_diffusion=True)\n",
    "    # plot_confusion_matrix(random_init, dgnn_init, model_name=model_name + 'GNN', color='lightcoral', if_diffusion=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QASM VQE Random Init Loss: 0.02\n",
      "QASM VQE Diff Init Loss: 0.02\n",
      "QASM VQE Qracle Init Loss: -0.08\n"
     ]
    }
   ],
   "source": [
    "random_init, diff_init, dgnn_init, _ = get_qasm_vqe_init_losses(vqe_valid_file)\n",
    "random_mean_init = np.mean(random_init)\n",
    "diff_mean_init = np.mean(diff_init)\n",
    "dgnn_mean_init = np.mean(dgnn_init)\n",
    "print(f\"QASM VQE Random Init Loss: {random_mean_init:.2f}\")\n",
    "print(f\"QASM VQE Diff Init Loss: {diff_mean_init:.2f}\")\n",
    "print(f\"QASM VQE Qracle Init Loss: {dgnn_mean_init:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11028/799688225.py:80: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  percentage_changes = [abs(loss_values[i+j+1] - loss_values[i+j])/total_height for j in range(plateau_steps)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QASM VQE Random Conv Steps: 237.82\n",
      "QASM VQE Diffusion Conv Steps: 250.26\n",
      "QASM VQE Qracle Conv Steps: 247.56\n"
     ]
    }
   ],
   "source": [
    "rand_conv_steps, diff_conv_steps, q_conv_steps = get_qasm_conv_steps(vqe_valid_file)\n",
    "print(f\"QASM VQE Random Conv Steps: {np.mean(rand_conv_steps):.2f}\")\n",
    "print(f\"QASM VQE Diffusion Conv Steps: {np.mean(diff_conv_steps):.2f}\")\n",
    "print(f\"QASM VQE Qracle Conv Steps: {np.mean(q_conv_steps):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heisenberg Random Conv Steps: 266.93\n",
      "Heisenberg Diffusion Conv Steps: 251.89\n",
      "Heisenberg Qracle Conv Steps: 187.47\n",
      "Transverse Ising Random Conv Steps: 235.93\n",
      "Transverse Ising Diffusion Conv Steps: 180.83\n",
      "Transverse Ising Qracle Conv Steps: 158.50\n",
      "Fermi-Hubbard Random Conv Steps: 218.46\n",
      "Fermi-Hubbard Diffusion Conv Steps: 213.21\n",
      "Fermi-Hubbard Qracle Conv Steps: 185.80\n",
      "H2 Random Conv Steps: 215.91\n",
      "H2 Diffusion Conv Steps: 600.00\n",
      "H2 Qracle Conv Steps: 574.64\n"
     ]
    }
   ],
   "source": [
    "for valid_file, model_name in zip(valid_files, model_names):\n",
    "    rand_conv_steps, diff_conv_steps, q_conv_steps = get_conv_steps(valid_file)\n",
    "    print(f\"{model_name} Random Conv Steps: {np.mean(rand_conv_steps):.2f}\")\n",
    "    print(f\"{model_name} Diffusion Conv Steps: {np.mean(diff_conv_steps):.2f}\")\n",
    "    print(f\"{model_name} Qracle Conv Steps: {np.mean(q_conv_steps):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pennylane",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
